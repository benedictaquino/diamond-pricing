{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from src.utilities import VIF, levenes_test\n",
    "from src.data_pipeline import data_clean\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset\n",
    "\n",
    "I've already split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = pd.read_csv('../data/train.csv', index_col=0)\n",
    "\n",
    "diamonds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15));\n",
    "sns.pairplot(diamonds, diag_kind='kde');\n",
    "plt.title(\"Scatter Matrix\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analyses of Continuous Features\n",
    "\n",
    "### `carat`\n",
    "\n",
    "Intuitively, I expect `carat` to be have a strong relationship with `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='carat', y='price', data=diamonds, alpha=0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks relatively linear. There appears to be a heteroskedastic relationship between carat and price. I'll fit a univariate linear regression on price and carat and test the residuals with a Breusch-Pagan test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Testing for Heteroskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['price']\n",
    "X = sm.add_constant(diamonds['carat'])\n",
    "\n",
    "lm_carat = sm.OLS(y, X)\n",
    "lm_carat_fitted = lm_carat.fit()\n",
    "\n",
    "lm_carat_fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = lm_carat_fitted.resid\n",
    "\n",
    "f_stat, p_val, alt = sm.stats.diagnostic.het_goldfeldquandt(y, X)\n",
    "\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fail to reject the null hypothesis that our data is homoskedastic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_resids = lm_carat_fitted.resid_pearson\n",
    "\n",
    "plt.figure(figsize=(15,10)); # I like big plots and I cannot lie\n",
    "plt.scatter(x=range(len(resids)), y=pearson_resids, alpha=0.2);\n",
    "plt.title(\"Standardized Residual Plot\");\n",
    "plt.axhline(c='black', ls='-.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, let's move on.\n",
    "\n",
    "#### Normal Distribution of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10));\n",
    "sm.qqplot(pearson_resids, ax=ax, line='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between this terrible looking Q-Q plot and the Jacques-Bera test, our error does not look normally distributed. Let's log transform this puppy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lny = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='carat', y=lny, data=diamonds, alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_log_carat = sm.OLS(lny, X)\n",
    "lm_log_carat_fitted = lm_log_carat.fit()\n",
    "\n",
    "lm_log_carat_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a lot better, quadratic probably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JB test is still significant (large sample size :\\) but the stat is much lower. Let's look at residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pearson_resids = lm_log_carat_fitted.resid_pearson\n",
    "\n",
    "plt.figure(figsize=(15,10)); # I like big plots and I cannot lie\n",
    "plt.scatter(x=range(len(resids)), y=log_pearson_resids, alpha=0.2);\n",
    "plt.title(\"Standardized Residual Plot\");\n",
    "plt.axhline(c='black', ls='-.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10));\n",
    "sm.qqplot(log_pearson_resids, ax=ax, line='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect, but nothing is. Let's move on, it looks good enough. We will proceed using the natty log of price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['lnprice'] = np.log(diamonds['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autocorrelation\n",
    "\n",
    "Recall that our Durbin-Watson test statistic was 1.992, so we're good there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "So our univariate analysis of carat and price shows we have an $R^2$ of 0.846, I guess we can call it a day! Just kidding. Let's check out our other features and see how a quadratic model stacks up.\n",
    "\n",
    "### `carat2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['carat2'] = diamonds['carat'] ** 2\n",
    "y = diamonds['lnprice']\n",
    "X = diamonds[['carat','carat2']]\n",
    "\n",
    "lm_carat2 = sm.OLS(y, X)\n",
    "lm_carat2_fitted = lm_carat2.fit()\n",
    "\n",
    "lm_carat2_fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_resids = lm_carat2_fitted.resid_pearson\n",
    "\n",
    "plt.figure(figsize=(15,10)); # I like big plots and I cannot lie\n",
    "plt.scatter(x=range(len(resids)), y=pearson_resids, alpha=0.2);\n",
    "plt.title(\"Standardized Residual Plot\");\n",
    "plt.axhline(c='black', ls='-.');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10));\n",
    "sm.qqplot(pearson_resids, ax=ax, line='s');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(lm_carat2_fitted.mse_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `x`, `y`, `z`, `depth`,  and `table`\n",
    "\n",
    "These all have to do with the dimensions and shape of the diamond, and even if there is some good stuff going on here I would bet all I got that there's a bunch of multicollinearity (amongst themselves and `carat`) as well. Let's check it out anyway.\n",
    "\n",
    "### `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='x', y='lnprice', data=diamonds, alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['lnprice']\n",
    "X = sm.add_constant(diamonds['x'])\n",
    "\n",
    "lm_x = sm.OLS(y, X)\n",
    "lm_x_fitted = lm_x.fit()\n",
    "\n",
    "lm_x_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heteroskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = lm_x_fitted.resid\n",
    "\n",
    "f_stat, p_val, alt = sm.stats.diagnostic.het_goldfeldquandt(y, X)\n",
    "\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_resids = lm_x_fitted.resid_pearson\n",
    "\n",
    "plt.figure(figsize=(15,10)); \n",
    "plt.scatter(x=range(len(resids)), y=pearson_resids, alpha=0.2);\n",
    "plt.title(\"Standardized Residual Plot\");\n",
    "plt.axhline(c='black', ls='-.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Distribution of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10));\n",
    "sm.qqplot(pearson_resids, ax=ax, line='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks okay.\n",
    "\n",
    "#### Autocorrelation\n",
    "\n",
    "D-W stat at 1.996, so we are good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='y', y='lnprice', data=diamonds, alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['lnprice']\n",
    "X = sm.add_constant(diamonds['y'])\n",
    "\n",
    "lm_y = sm.OLS(y, X)\n",
    "lm_y_fitted = lm_y.fit()\n",
    "\n",
    "lm_y_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heteroskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = lm_y_fitted.resid\n",
    "\n",
    "f_stat, p_val, alt = sm.stats.diagnostic.het_goldfeldquandt(y, X)\n",
    "\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, doesn't look so good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_resids = lm_y_fitted.resid_pearson\n",
    "\n",
    "plt.figure(figsize=(15,10)); \n",
    "plt.scatter(x=range(len(resids)), y=pearson_resids, alpha=0.2);\n",
    "plt.title(\"Standardized Residual Plot\");\n",
    "plt.axhline(c='black', ls='-.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's just a couple of outliers messing it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Distribution of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10));\n",
    "sm.qqplot(pearson_resids, ax=ax, line='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks bad\n",
    "\n",
    "#### Autocorrelation\n",
    "\n",
    "D-W stat at 1.990, so we are good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='z', y='lnprice', data=diamonds, alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['lnprice']\n",
    "X = sm.add_constant(diamonds['z'])\n",
    "\n",
    "lm_z = sm.OLS(y, X)\n",
    "lm_z_fitted = lm_z.fit()\n",
    "\n",
    "lm_z_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heteroskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = lm_z_fitted.resid\n",
    "\n",
    "f_stat, p_val, alt = sm.stats.diagnostic.het_goldfeldquandt(y, X)\n",
    "\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_resids = lm_z_fitted.resid_pearson\n",
    "\n",
    "plt.figure(figsize=(15,10)); \n",
    "plt.scatter(x=range(len(resids)), y=pearson_resids, alpha=0.2);\n",
    "plt.title(\"Standardized Residual Plot\");\n",
    "plt.axhline(c='black', ls='-.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's just a couple of outliers messing it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Distribution of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10));\n",
    "sm.qqplot(pearson_resids, ax=ax, line='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks  fine\n",
    "\n",
    "#### Autocorrelation\n",
    "\n",
    "D-W stat at 1.994, so we are good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `depth`\n",
    "\n",
    "This one is literally a function of `x`, `y`, and `z`.\n",
    "\n",
    "<center>$depth = \\displaystyle \\frac{2z}{x + y}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='depth', y='lnprice', data=diamonds, alpha=0.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kinda looks like it goes straight up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['lnprice']\n",
    "X = sm.add_constant(diamonds['depth'])\n",
    "\n",
    "lm_depth = sm.OLS(y, X)\n",
    "lm_depth_fitted = lm_depth.fit()\n",
    "\n",
    "lm_depth_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, hah smell ya later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='table', y='lnprice', data=diamonds, alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['lnprice']\n",
    "X = sm.add_constant(diamonds['table'])\n",
    "\n",
    "lm_table = sm.OLS(y, X)\n",
    "lm_table_fitted = lm_table.fit()\n",
    "\n",
    "lm_table_fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(lm_table_fitted.mse_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "So our univariate analyses indicate that `carat`, `x`, `y`, and `z` are good features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features\n",
    "\n",
    "### `cut`\n",
    "\n",
    "Note: values for this are `Fair`, `Good`, `Very Good`, `Premium`, and `Ideal`. Ideal being best, and Fair being worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['cut'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='carat', y='lnprice', data=diamonds, alpha=0.4, hue='cut', cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.boxplot(x='cut', y='lnprice', data=diamonds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variances look alright from the boxplots, but we should do a Levene's Test to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levenes_test(diamonds['lnprice'], diamonds['cut'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variances are not homogenous, so I shouldn't add it to my model, and visual inspection of the boxplots and scatter plot indicate that it isn't a very impactful feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `color`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(diamonds['color'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='carat', y='lnprice', data=diamonds, alpha=0.4, hue='color', cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.boxplot(x='color', y='lnprice', data=diamonds, order=sorted(diamonds['color'].unique()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variances look alright from the boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levenes_test(diamonds['lnprice'], diamonds['color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our test is significant indicating that `color` violates the assumption of homogeneity of variances, but based on the boxplot it does look like `color` could be a good indicator. Here I'm gonna make a judgement call and keep color, since large sample sizes just lead to low p-values. We have a fairly large data set (>40,000 observations), so p-values are going to be low even if the violations are negligible. \n",
    "\n",
    "\n",
    "I want to try combining categories. I'll run some pairwise t-tests first. Since I'll be doing multiple comparisons, I'll need to consider this when evaluating my p-vaklues. A bonferroni correction is appropriate here.\n",
    "\n",
    "First I'll do pairwise comparisons of the color grades with the next worst color grade, so there are 6 comparisons there, and my significance level $\\alpha = 0.05$ becomes $\\displaystyle \\frac{\\alpha}{m}=\\frac{0.05}{6}=0.008333$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {color: diamonds['lnprice'][diamonds['color'] == color] for color in sorted(diamonds['color'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(color_dict['D'], color_dict['E'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(color_dict['E'], color_dict['F'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(color_dict['F'], color_dict['G'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(color_dict['G'], color_dict['H'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(color_dict['H'], color_dict['I'], equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(color_dict['I'], color_dict['J'], equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we can combine a few categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['recolor'] = diamonds['color']\n",
    "\n",
    "diamonds['recolor'].replace(to_replace='D', value='DE', inplace=True)\n",
    "diamonds['recolor'].replace(to_replace='E', value='DE', inplace=True)\n",
    "diamonds['recolor'].replace(to_replace='F', value='FG', inplace=True)\n",
    "diamonds['recolor'].replace(to_replace='G', value='FG', inplace=True)\n",
    "\n",
    "levenes_test(diamonds['lnprice'], diamonds['recolor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='carat', y='lnprice', data=diamonds, alpha=0.4, hue='recolor', cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.boxplot(x='recolor', y='lnprice', data=diamonds, order=sorted(diamonds['recolor'].unique()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `clarity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['clarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_clarity = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.scatterplot(x='carat', y='lnprice', data=diamonds, alpha=0.4, hue='clarity', cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10));\n",
    "sns.boxplot(x='clarity', y='lnprice', data=diamonds, order=sorted_clarity);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variances look bad here, and the worst clarity grades have many outliers on the low end, and the best clarity grade has many outliers on the high end. I'm just going to disregard this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['lnprice']\n",
    "X = sm.add_constant(diamonds[['carat', 'carat2', 'x', 'y', 'z']])\n",
    "\n",
    "lm_multi = sm.OLS(y, X)\n",
    "lm_multi_fitted = lm_multi.fit()\n",
    "\n",
    "lm_multi_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multicollinearity\n",
    "\n",
    "The condition number of 346 indicates multicollinearity. Intuitively, it makes sense that the weight (`carat`) and volume (`x`, `y`, `z`) would be correlated. We can use the Variance Inflation Factor to measure collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF(X.drop(columns='const'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as expected,`x`, `y`, and `z` have ridiculous VIF's. Let's move on with just `carat` and `carat2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['lnprice']\n",
    "X = sm.add_constant(diamonds[['carat', 'carat2']])\n",
    "\n",
    "lm_multi2 = sm.OLS(y, X)\n",
    "lm_multi2_fitted = lm_multi2.fit()\n",
    "\n",
    "lm_multi2_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that I want to add `recolor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['lnprice']\n",
    "X = sm.add_constant(pd.get_dummies(diamonds[['carat', 'carat2', 'recolor']], drop_first=True))\n",
    "\n",
    "lm_multi_color = sm.OLS(y, X)\n",
    "lm_multi_color_fitted = lm_multi_color.fit()\n",
    "\n",
    "lm_multi_color_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validate with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diamonds['lnprice']\n",
    "X = pd.get_dummies(diamonds[['carat', 'carat2', 'recolor']], drop_first=True)\n",
    "\n",
    "linear = LinearRegression(n_jobs=-1)\n",
    "\n",
    "np.mean(cross_val_score(linear, X, y, n_jobs=-1, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.25, 0.5, 1, 2, 3, 5, 10]}\n",
    "\n",
    "cv = GridSearchCV(ridge, param_grid)\n",
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "param_grid = {'alpha': np.linspace(1,3)}\n",
    "\n",
    "cv = GridSearchCV(ridge, param_grid, n_jobs=-1)\n",
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "\n",
    "param_grid = {'alpha': np.linspace(2.25,2.27)}\n",
    "\n",
    "cv = GridSearchCV(ridge, param_grid, n_jobs=-1)\n",
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "param_grid = {'alpha': np.linspace(0.001,10)}\n",
    "\n",
    "cv = GridSearchCV(lasso, param_grid, n_jobs=-1)\n",
    "cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal improvement with Ridge Regression, let's just move forward without any regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_clean(pd.read_csv('../data/test.csv', index_col=0))\n",
    "\n",
    "y_train = diamonds['lnprice']\n",
    "X_train = pd.get_dummies(diamonds[['carat', 'carat2', 'recolor']], drop_first=True)\n",
    "\n",
    "y_test = test['lnprice']\n",
    "X_test = pd.get_dummies(test[['carat', 'carat2', 'recolor']], drop_first=True)\n",
    "\n",
    "linear = LinearRegression(n_jobs=-1)\n",
    "linear.fit(X_train,y_train)\n",
    "linear.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_final = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "lm_final = lm_final.fit()\n",
    "\n",
    "lm_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x='carat', y='lnprice', data=diamonds, alpha=0.4, hue='recolor', cmap='viridis');\n",
    "sns.regplot(x='carat', y=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
